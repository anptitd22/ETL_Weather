{"timestamp":"2025-07-11T20:00:02.644151","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-11T20:00:02.646840","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-11T20:00:03.453940Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.563174Z","level":"error","event":"25/07/11 20:00:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.564132Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.564581Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.565064Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.565503Z","level":"error","event":"Exception in thread \"main\" java.nio.file.NoSuchFileException: /tmp/tmp82edjs4c/connection11999048569425080177.info","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.566171Z","level":"error","event":"\tat java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.566602Z","level":"error","event":"\tat java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:106)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.566933Z","level":"error","event":"\tat java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.567232Z","level":"error","event":"\tat java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:218)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.567548Z","level":"error","event":"\tat java.base/java.nio.file.Files.newByteChannel(Files.java:380)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.567826Z","level":"error","event":"\tat java.base/java.nio.file.Files.createFile(Files.java:658)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.568167Z","level":"error","event":"\tat java.base/java.nio.file.TempFileHelper.create(TempFileHelper.java:136)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.568575Z","level":"error","event":"\tat java.base/java.nio.file.TempFileHelper.createTempFile(TempFileHelper.java:159)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.568874Z","level":"error","event":"\tat java.base/java.nio.file.Files.createTempFile(Files.java:878)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.569231Z","level":"error","event":"\tat org.apache.spark.api.python.PythonGatewayServer$.main(PythonGatewayServer.scala:55)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.569516Z","level":"error","event":"\tat org.apache.spark.api.python.PythonGatewayServer.main(PythonGatewayServer.scala)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.569821Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.570088Z","level":"error","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.570397Z","level":"error","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.570655Z","level":"error","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.570997Z","level":"error","event":"\tat org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.571290Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1027)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.571568Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:204)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.571819Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:227)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.572188Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:96)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.572568Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1132)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.572801Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1141)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.573053Z","level":"error","event":"\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","chan":"stderr","logger":"task"}
{"timestamp":"2025-07-11T20:00:37.753426","level":"error","event":"Process timed out, PID: 4323","logger":"airflow.utils.timeout.TimeoutPosix"}
{"timestamp":"2025-07-11T20:00:38.963031","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"AirflowTaskTimeout","exc_value":"DagBag import timeout for /opt/airflow/dags/main.py after 30.0s.\nPlease take a look at these docs to improve your DAG import time:\n* https://airflow.apache.org/docs/apache-airflow/3.0.0/best-practices.html#top-level-python-code\n* https://airflow.apache.org/docs/apache-airflow/3.0.0/best-practices.html#reducing-dag-complexity, PID: 4323","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":6,"name":"<module>"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":55,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py","lineno":556,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":523,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":205,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":444,"name":"_ensure_initialized"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/java_gateway.py","lineno":107,"name":"launch_gateway"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py","lineno":69,"name":"handle_timeout"}]}]}
{"timestamp":"2025-07-11T20:00:38.993578","level":"error","event":"DAG not found during start up","dag_id":"etl_pipeline","bundle":"BundleInfo(name='dags-folder', version=None)","path":"main.py","logger":"task"}
{"timestamp":"2025-07-11T20:00:40.574779Z","level":"warning","event":"Process exited abnormally","exit_code":1,"logger":"task"}
