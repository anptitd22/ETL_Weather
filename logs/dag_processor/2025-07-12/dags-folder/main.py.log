{"timestamp":"2025-07-12T14:34:18.767752","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-12T14:34:22.359456Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:34:24.849045Z","level":"error","event":"25/07/12 14:34:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:34:25.722019Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:34:25.723687Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:34:25.725166Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:34:27.909792Z","level":"error","event":"25/07/12 14:34:27 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:34:34.490397","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"ModuleNotFoundError","exc_value":"No module named 'dataset.weather_data_api'","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":7,"name":"<module>"}]}]}
{"timestamp":"2025-07-12T14:35:05.359901","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-12T14:35:05.922116Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:35:09.231166Z","level":"error","event":"25/07/12 14:35:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:35:09.917165Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:35:09.937752Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:35:09.938372Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:35:12.340903Z","level":"error","event":"25/07/12 14:35:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:35:36.415915","level":"error","event":"Process timed out, PID: 424","logger":"airflow.utils.timeout.TimeoutPosix"}
{"timestamp":"2025-07-12T14:35:38.589486","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"AirflowTaskTimeout","exc_value":"DagBag import timeout for /opt/airflow/dags/main.py after 30.0s.\nPlease take a look at these docs to improve your DAG import time:\n* https://airflow.apache.org/docs/apache-airflow/3.0.0/best-practices.html#top-level-python-code\n* https://airflow.apache.org/docs/apache-airflow/3.0.0/best-practices.html#reducing-dag-complexity, PID: 424","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":6,"name":"<module>"},{"filename":"/opt/airflow/dags/etl_data_weather.py","lineno":15,"name":"<module>"},{"filename":"/opt/airflow/dags/spark/build_spark.py","lineno":58,"name":"get_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/session.py","lineno":556,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":523,"name":"getOrCreate"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":207,"name":"__init__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/core/context.py","lineno":302,"name":"_do_init"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1361,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1038,"name":"send_command"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/clientserver.py","lineno":535,"name":"send_command"},{"filename":"/usr/local/lib/python3.12/socket.py","lineno":720,"name":"readinto"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/timeout.py","lineno":69,"name":"handle_timeout"}]}]}
{"timestamp":"2025-07-12T14:36:11.571257","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-12T14:36:12.082828Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:36:14.366149Z","level":"error","event":"25/07/12 14:36:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:36:14.660062Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:36:14.660389Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:36:14.660686Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:36:15.904303Z","level":"error","event":"25/07/12 14:36:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:36:23.582294","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"ModuleNotFoundError","exc_value":"No module named 'dataset.weather_data_api'","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":7,"name":"<module>"}]}]}
{"timestamp":"2025-07-12T14:36:55.129819","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-12T14:36:55.684527Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:36:57.939000Z","level":"error","event":"25/07/12 14:36:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:36:58.202418Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:36:58.210832Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:36:58.211337Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:36:59.348997Z","level":"error","event":"25/07/12 14:36:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:36:59.349389Z","level":"error","event":"25/07/12 14:36:59 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:37:05.473702","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"ModuleNotFoundError","exc_value":"No module named 'dataset.weather_data_api'","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":7,"name":"<module>"}]}]}
{"timestamp":"2025-07-12T14:37:36.047780","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-12T14:37:36.395356Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:37:37.833728Z","level":"error","event":"25/07/12 14:37:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:37:38.052992Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:37:38.053404Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:37:38.053867Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:37:40.994594Z","level":"error","event":"25/07/12 14:37:40 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:37:45.698616","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"ModuleNotFoundError","exc_value":"No module named 'dataset.weather_data_api'","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":7,"name":"<module>"}]}]}
{"timestamp":"2025-07-12T14:38:16.472816","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-12T14:38:17.078346Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:38:18.418075Z","level":"error","event":"25/07/12 14:38:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:38:18.609499Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:38:18.616566Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:38:18.617208Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:38:19.669379Z","level":"error","event":"25/07/12 14:38:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:38:23.248110","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"ModuleNotFoundError","exc_value":"No module named 'dataset.weather_data_api'","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":7,"name":"<module>"}]}]}
{"timestamp":"2025-07-12T14:38:54.016245","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-12T14:38:55.196761Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:38:57.216942Z","level":"error","event":"25/07/12 14:38:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:38:57.475420Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:38:57.475763Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:38:57.476034Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:39:04.862684","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"ModuleNotFoundError","exc_value":"No module named 'dataset.weather_data_api'","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":7,"name":"<module>"}]}]}
{"timestamp":"2025-07-12T14:39:35.605216","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-12T14:39:36.559141Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:39:38.428717Z","level":"error","event":"25/07/12 14:39:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:39:38.660446Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:39:38.660958Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:39:38.661358Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:39:44.338564","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"ModuleNotFoundError","exc_value":"No module named 'dataset.weather_data_api'","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":7,"name":"<module>"}]}]}
{"timestamp":"2025-07-12T14:40:15.324353","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-12T14:40:15.763033Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:40:17.971029Z","level":"error","event":"25/07/12 14:40:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:40:18.256721Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:40:18.264861Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:40:18.265366Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:40:25.099016","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"ModuleNotFoundError","exc_value":"No module named 'dataset.weather_data_api'","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":7,"name":"<module>"}]}]}
{"timestamp":"2025-07-12T14:40:55.931374","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-12T14:40:56.332791Z","level":"error","event":"WARNING: Using incubator modules: jdk.incubator.vector","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:40:57.778953Z","level":"error","event":"25/07/12 14:40:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:40:57.996508Z","level":"error","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:40:58.003373Z","level":"error","event":"Setting default log level to \"WARN\".","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:40:58.003847Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","chan":"stderr","logger":"processor"}
{"timestamp":"2025-07-12T14:41:03.420966","level":"error","event":"Failed to import: /opt/airflow/dags/main.py","logger":"airflow.models.dagbag.DagBag","error_detail":[{"exc_type":"ModuleNotFoundError","exc_value":"No module named 'dataset.weather_data_api'","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py","lineno":384,"name":"parse"},{"filename":"<frozen importlib._bootstrap_external>","lineno":999,"name":"exec_module"},{"filename":"<frozen importlib._bootstrap>","lineno":488,"name":"_call_with_frames_removed"},{"filename":"/opt/airflow/dags/main.py","lineno":7,"name":"<module>"}]}]}
